{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from keras import Sequential\nfrom sklearn.model_selection import train_test_split\nfrom keras.applications import ResNet50\nfrom keras.applications.resnet_v2 import preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import SGD, Adam\nfrom keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\nfrom keras.layers import Flatten, Dense, Dropout, BatchNormalization\nfrom keras.utils import to_categorical\nfrom keras.datasets import cifar10\nimport pandas as pd\nimport pickle \n\ndef resnet_accuracies(froze=False, LR_scheduler='Plateau', augmentation=True, batch_size=100, epochs=20, learn_rate=.001):\n    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n#     x_train = preprocess_input(x_train)\n#     x_test = preprocess_input(x_test)\n    \n    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3)\n\n    y_train = to_categorical(y_train)\n    y_val = to_categorical(y_val)\n    y_test = to_categorical(y_test)\n\n    train_generator = ImageDataGenerator(\n        rotation_range=2,\n        horizontal_flip=True,\n        zoom_range=.1)\n\n    val_generator = ImageDataGenerator(\n        rotation_range=2,\n        horizontal_flip=True,\n        zoom_range=.1)\n\n    test_generator = ImageDataGenerator(\n        rotation_range=2,\n        horizontal_flip=True,\n        zoom_range=.1)\n    train_generator.fit(x_train)\n    val_generator.fit(x_val)\n    test_generator.fit(x_test) \n    \n    # setting learning rate schedulers\n    def scheduler(epoch):\n        if epoch < 5:\n            return learn_rate \n        if epoch < 20:\n            return learn_rate /10\n        return learn_rate/100\n    if LR_scheduler == 'Custom' :\n        callbacks = [LearningRateScheduler(scheduler)]\n    elif LR_scheduler == 'Plateau' :\n        callbacks = [ReduceLROnPlateau(\n        monitor='val_accuracy',\n        factor=.01,\n        patience=3,\n        min_lr=1e-5)]\n    else :\n        callbacks = [LearningRateScheduler(lambda x: learn_rate)]\n    base_model = ResNet50(include_top=False, weights='imagenet', input_shape=x_train.shape[1:],\n                          classes=y_train.shape[1])\n\n    model = Sequential()\n    model.add(base_model)\n    model.add(Flatten())\n    model.add(BatchNormalization(momentum=0.9, epsilon=1e-5))\n    model.add(Dense(256, activation='relu', input_dim=512))\n    model.add(Dropout(.5))\n    model.add(BatchNormalization(momentum=0.9, epsilon=1e-5))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(.5))\n    model.add(BatchNormalization(momentum=0.9, epsilon=1e-5))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(.5))\n    model.add(BatchNormalization(momentum=0.9, epsilon=1e-5))\n    model.add(Dense(32, activation='relu'))\n    model.add(Dense(10, activation='softmax'))\n\n    model.layers[0].trainable = not froze\n\n    adam = Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n    if augmentation:\n        history = model.fit(train_generator.flow(x_train, y_train, batch_size=batch_size),\n                  epochs=epochs, steps_per_epoch=x_train.shape[0] // batch_size,\n                  validation_data=val_generator.flow(x_val, y_val, batch_size=batch_size), validation_steps=10,\n                  callbacks=callbacks, verbose=1)\n    else:\n        history = model.fit(x_train, y_train, batch_size=batch_size,\n                  epochs=epochs, steps_per_epoch=x_train.shape[0] // batch_size,\n                  validation_data=(x_val, y_val), validation_steps=10,\n                  callbacks=callbacks, verbose=1)\n    return {**history.history, 'test_accuracy': (model.predict(x_test).argmax(axis=1) == y_test.argmax(axis=1)).mean()}\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"experiments = [{'name': 'Base model',\n                'kwargs': {}},\n               {'name': 'Frozen',\n                'kwargs': {'froze': True}},\n               {'name': 'No scheduler',\n                'kwargs': {'LR_scheduler': None}},\n               {'name': 'Custom scheduler',\n                'kwargs': {'LR_scheduler': 'Custom'}},\n               {'name': 'No augmentation',\n                'kwargs': {'augmentation': False}},\n               \n               \n              ]\nfor i in range(3):\n    assessment = pd.DataFrame([{**resnet_accuracies(**exp['kwargs']),\n                               'name': exp['name']} for exp in experiments])\n    assessment.to_pickle(f'assessment_{i}.pkl')","metadata":{"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/20\n350/350 [==============================] - 39s 90ms/step - loss: 2.4161 - accuracy: 0.1283 - val_loss: 1.8292 - val_accuracy: 0.3040\nEpoch 2/20\n350/350 [==============================] - 30s 86ms/step - loss: 1.7640 - accuracy: 0.3132 - val_loss: 1.6980 - val_accuracy: 0.4040\nEpoch 3/20\n350/350 [==============================] - 30s 86ms/step - loss: 1.4074 - accuracy: 0.4923 - val_loss: 1.9417 - val_accuracy: 0.4670\nEpoch 4/20\n350/350 [==============================] - 30s 85ms/step - loss: 1.2068 - accuracy: 0.5927 - val_loss: 1.6043 - val_accuracy: 0.5400\nEpoch 5/20\n350/350 [==============================] - 30s 85ms/step - loss: 1.0883 - accuracy: 0.6508 - val_loss: 1.7373 - val_accuracy: 0.4770\nEpoch 6/20\n350/350 [==============================] - 30s 85ms/step - loss: 0.9926 - accuracy: 0.6847 - val_loss: 1.1229 - val_accuracy: 0.6340\nEpoch 7/20\n350/350 [==============================] - 30s 85ms/step - loss: 0.9421 - accuracy: 0.7058 - val_loss: 1.1261 - val_accuracy: 0.6550\nEpoch 8/20\n350/350 [==============================] - 30s 85ms/step - loss: 0.8551 - accuracy: 0.7380 - val_loss: 1.0813 - val_accuracy: 0.6530\nEpoch 9/20\n350/350 [==============================] - 31s 87ms/step - loss: 0.8143 - accuracy: 0.7491 - val_loss: 1.1386 - val_accuracy: 0.6230\nEpoch 10/20\n350/350 [==============================] - 30s 86ms/step - loss: 0.7629 - accuracy: 0.7676 - val_loss: 1.3305 - val_accuracy: 0.6060\nEpoch 11/20\n350/350 [==============================] - 30s 87ms/step - loss: 0.6842 - accuracy: 0.7946 - val_loss: 0.6615 - val_accuracy: 0.7820\nEpoch 12/20\n350/350 [==============================] - 30s 86ms/step - loss: 0.6715 - accuracy: 0.8014 - val_loss: 0.6727 - val_accuracy: 0.7760\nEpoch 13/20\n350/350 [==============================] - 30s 87ms/step - loss: 0.6249 - accuracy: 0.8126 - val_loss: 0.6368 - val_accuracy: 0.8000\nEpoch 14/20\n350/350 [==============================] - 30s 86ms/step - loss: 0.6226 - accuracy: 0.8135 - val_loss: 0.6264 - val_accuracy: 0.7880\nEpoch 15/20\n350/350 [==============================] - 31s 87ms/step - loss: 0.6060 - accuracy: 0.8215 - val_loss: 0.5741 - val_accuracy: 0.8070\nEpoch 16/20\n350/350 [==============================] - 29s 83ms/step - loss: 0.5958 - accuracy: 0.8213 - val_loss: 0.5966 - val_accuracy: 0.8180\nEpoch 17/20\n350/350 [==============================] - 30s 85ms/step - loss: 0.5697 - accuracy: 0.8339 - val_loss: 0.5849 - val_accuracy: 0.8190\nEpoch 18/20\n350/350 [==============================] - 29s 83ms/step - loss: 0.5742 - accuracy: 0.8290 - val_loss: 0.6172 - val_accuracy: 0.8120\nEpoch 19/20\n350/350 [==============================] - 30s 85ms/step - loss: 0.5752 - accuracy: 0.8289 - val_loss: 0.5912 - val_accuracy: 0.8160\nEpoch 20/20\n350/350 [==============================] - 30s 85ms/step - loss: 0.5547 - accuracy: 0.8351 - val_loss: 0.5998 - val_accuracy: 0.8160\nEpoch 1/20\n350/350 [==============================] - 29s 71ms/step - loss: 2.2226 - accuracy: 0.2002 - val_loss: 1.5541 - val_accuracy: 0.4770\nEpoch 2/20\n350/350 [==============================] - 24s 68ms/step - loss: 1.6514 - accuracy: 0.4030 - val_loss: 1.3577 - val_accuracy: 0.5020\nEpoch 3/20\n350/350 [==============================] - 24s 69ms/step - loss: 1.4976 - accuracy: 0.4708 - val_loss: 1.2722 - val_accuracy: 0.5550\nEpoch 4/20\n350/350 [==============================] - 24s 69ms/step - loss: 1.4324 - accuracy: 0.5004 - val_loss: 1.2806 - val_accuracy: 0.5710\nEpoch 5/20\n350/350 [==============================] - 23s 66ms/step - loss: 1.3973 - accuracy: 0.5145 - val_loss: 1.2515 - val_accuracy: 0.5720\nEpoch 6/20\n350/350 [==============================] - 24s 68ms/step - loss: 1.3491 - accuracy: 0.5421 - val_loss: 1.2518 - val_accuracy: 0.5790\nEpoch 7/20\n350/350 [==============================] - 24s 69ms/step - loss: 1.3305 - accuracy: 0.5465 - val_loss: 1.2123 - val_accuracy: 0.5950\nEpoch 8/20\n350/350 [==============================] - 23s 67ms/step - loss: 1.3127 - accuracy: 0.5490 - val_loss: 1.1630 - val_accuracy: 0.6040\nEpoch 9/20\n350/350 [==============================] - 24s 67ms/step - loss: 1.2898 - accuracy: 0.5592 - val_loss: 1.2238 - val_accuracy: 0.5870\nEpoch 10/20\n350/350 [==============================] - 24s 67ms/step - loss: 1.2692 - accuracy: 0.5697 - val_loss: 1.1780 - val_accuracy: 0.6000\nEpoch 11/20\n350/350 [==============================] - 23s 67ms/step - loss: 1.2581 - accuracy: 0.5761 - val_loss: 1.1503 - val_accuracy: 0.6200\nEpoch 12/20\n350/350 [==============================] - 23s 65ms/step - loss: 1.2523 - accuracy: 0.5761 - val_loss: 1.1791 - val_accuracy: 0.6150\nEpoch 13/20\n350/350 [==============================] - 24s 68ms/step - loss: 1.2423 - accuracy: 0.5791 - val_loss: 1.1550 - val_accuracy: 0.6060\nEpoch 14/20\n350/350 [==============================] - 24s 69ms/step - loss: 1.2228 - accuracy: 0.5895 - val_loss: 1.1588 - val_accuracy: 0.6200\nEpoch 15/20\n350/350 [==============================] - 23s 67ms/step - loss: 1.2060 - accuracy: 0.5932 - val_loss: 1.1424 - val_accuracy: 0.6070\nEpoch 16/20\n350/350 [==============================] - 23s 66ms/step - loss: 1.2007 - accuracy: 0.5958 - val_loss: 1.1644 - val_accuracy: 0.6030\nEpoch 17/20\n350/350 [==============================] - 24s 70ms/step - loss: 1.2103 - accuracy: 0.5885 - val_loss: 1.1301 - val_accuracy: 0.6240\nEpoch 18/20\n350/350 [==============================] - 24s 69ms/step - loss: 1.1985 - accuracy: 0.5961 - val_loss: 1.1602 - val_accuracy: 0.5930\nEpoch 19/20\n350/350 [==============================] - 24s 67ms/step - loss: 1.1976 - accuracy: 0.6012 - val_loss: 1.1420 - val_accuracy: 0.6010\nEpoch 20/20\n350/350 [==============================] - 24s 69ms/step - loss: 1.2082 - accuracy: 0.5988 - val_loss: 1.1856 - val_accuracy: 0.5870\nEpoch 1/20\n350/350 [==============================] - 38s 87ms/step - loss: 2.3602 - accuracy: 0.1486 - val_loss: 2.1301 - val_accuracy: 0.2910\nEpoch 2/20\n350/350 [==============================] - 28s 79ms/step - loss: 1.6358 - accuracy: 0.3688 - val_loss: 1.6087 - val_accuracy: 0.4520\nEpoch 3/20\n350/350 [==============================] - 29s 82ms/step - loss: 1.3215 - accuracy: 0.5320 - val_loss: 1.4363 - val_accuracy: 0.5000\nEpoch 4/20\n350/350 [==============================] - 29s 84ms/step - loss: 1.1611 - accuracy: 0.6111 - val_loss: 1.5507 - val_accuracy: 0.5440\nEpoch 5/20\n350/350 [==============================] - 30s 85ms/step - loss: 1.0310 - accuracy: 0.6710 - val_loss: 1.4746 - val_accuracy: 0.5460\nEpoch 6/20\n350/350 [==============================] - 29s 84ms/step - loss: 0.9292 - accuracy: 0.7079 - val_loss: 0.9580 - val_accuracy: 0.7000\nEpoch 7/20\n350/350 [==============================] - 30s 85ms/step - loss: 0.8734 - accuracy: 0.7283 - val_loss: 1.6052 - val_accuracy: 0.5840\nEpoch 8/20\n350/350 [==============================] - 29s 83ms/step - loss: 0.8215 - accuracy: 0.7477 - val_loss: 1.1814 - val_accuracy: 0.6610\nEpoch 9/20\n350/350 [==============================] - 30s 85ms/step - loss: 0.7772 - accuracy: 0.7584 - val_loss: 1.3425 - val_accuracy: 0.6060\nEpoch 10/20\n350/350 [==============================] - 28s 81ms/step - loss: 0.7449 - accuracy: 0.7704 - val_loss: 1.2435 - val_accuracy: 0.6280\nEpoch 11/20\n350/350 [==============================] - 29s 83ms/step - loss: 0.7108 - accuracy: 0.7892 - val_loss: 0.8434 - val_accuracy: 0.7290\nEpoch 12/20\n350/350 [==============================] - 30s 85ms/step - loss: 0.6765 - accuracy: 0.7951 - val_loss: 1.0605 - val_accuracy: 0.6580\nEpoch 13/20\n350/350 [==============================] - 28s 81ms/step - loss: 0.6652 - accuracy: 0.8012 - val_loss: 1.6457 - val_accuracy: 0.5690\nEpoch 14/20\n350/350 [==============================] - 28s 79ms/step - loss: 0.6159 - accuracy: 0.8153 - val_loss: 1.1096 - val_accuracy: 0.6540\nEpoch 15/20\n350/350 [==============================] - 29s 81ms/step - loss: 0.6331 - accuracy: 0.8150 - val_loss: 0.9132 - val_accuracy: 0.7120\nEpoch 16/20\n350/350 [==============================] - 28s 80ms/step - loss: 0.6045 - accuracy: 0.8187 - val_loss: 0.9756 - val_accuracy: 0.7010\nEpoch 17/20\n350/350 [==============================] - 28s 81ms/step - loss: 0.5462 - accuracy: 0.8390 - val_loss: 0.7450 - val_accuracy: 0.7650\nEpoch 18/20\n350/350 [==============================] - 28s 79ms/step - loss: 0.5326 - accuracy: 0.8437 - val_loss: 0.8879 - val_accuracy: 0.7320\nEpoch 19/20\n350/350 [==============================] - 29s 83ms/step - loss: 0.5232 - accuracy: 0.8454 - val_loss: 0.8031 - val_accuracy: 0.7550\nEpoch 20/20\n350/350 [==============================] - 28s 81ms/step - loss: 0.5065 - accuracy: 0.8530 - val_loss: 1.0473 - val_accuracy: 0.6930\nEpoch 1/20\n350/350 [==============================] - 37s 85ms/step - loss: 2.3186 - accuracy: 0.1625 - val_loss: 2.3079 - val_accuracy: 0.3450\nEpoch 2/20\n350/350 [==============================] - 28s 79ms/step - loss: 1.5337 - accuracy: 0.4269 - val_loss: 1.5573 - val_accuracy: 0.5130\nEpoch 3/20\n350/350 [==============================] - 29s 81ms/step - loss: 1.2071 - accuracy: 0.6022 - val_loss: 2.2282 - val_accuracy: 0.3760\nEpoch 4/20\n350/350 [==============================] - 28s 81ms/step - loss: 1.0737 - accuracy: 0.6604 - val_loss: 1.9890 - val_accuracy: 0.4830\nEpoch 5/20\n350/350 [==============================] - 29s 82ms/step - loss: 0.9829 - accuracy: 0.6921 - val_loss: 1.1500 - val_accuracy: 0.6280\nEpoch 6/20\n350/350 [==============================] - 29s 81ms/step - loss: 0.8300 - accuracy: 0.7435 - val_loss: 0.7704 - val_accuracy: 0.7420\nEpoch 7/20\n350/350 [==============================] - 28s 81ms/step - loss: 0.7295 - accuracy: 0.7818 - val_loss: 0.6691 - val_accuracy: 0.7760\nEpoch 8/20\n350/350 [==============================] - 29s 82ms/step - loss: 0.6875 - accuracy: 0.7944 - val_loss: 0.6626 - val_accuracy: 0.7950\nEpoch 9/20\n350/350 [==============================] - 28s 80ms/step - loss: 0.6338 - accuracy: 0.8140 - val_loss: 0.6504 - val_accuracy: 0.8060\nEpoch 10/20\n350/350 [==============================] - 29s 82ms/step - loss: 0.5967 - accuracy: 0.8258 - val_loss: 0.6419 - val_accuracy: 0.8000\nEpoch 11/20\n350/350 [==============================] - 28s 81ms/step - loss: 0.5655 - accuracy: 0.8330 - val_loss: 0.6971 - val_accuracy: 0.7860\nEpoch 12/20\n350/350 [==============================] - 29s 82ms/step - loss: 0.5324 - accuracy: 0.8420 - val_loss: 0.6990 - val_accuracy: 0.7880\nEpoch 13/20\n350/350 [==============================] - 29s 82ms/step - loss: 0.5148 - accuracy: 0.8488 - val_loss: 0.6464 - val_accuracy: 0.8120\nEpoch 14/20\n350/350 [==============================] - 28s 80ms/step - loss: 0.5010 - accuracy: 0.8552 - val_loss: 0.6209 - val_accuracy: 0.8080\nEpoch 15/20\n350/350 [==============================] - 29s 81ms/step - loss: 0.4510 - accuracy: 0.8698 - val_loss: 0.5704 - val_accuracy: 0.8280\nEpoch 16/20\n350/350 [==============================] - 28s 81ms/step - loss: 0.4305 - accuracy: 0.8792 - val_loss: 0.6510 - val_accuracy: 0.8080\nEpoch 17/20\n350/350 [==============================] - 28s 80ms/step - loss: 0.4093 - accuracy: 0.8841 - val_loss: 0.6738 - val_accuracy: 0.8120\nEpoch 18/20\n350/350 [==============================] - 29s 84ms/step - loss: 0.4007 - accuracy: 0.8873 - val_loss: 0.6268 - val_accuracy: 0.8250\nEpoch 19/20\n350/350 [==============================] - 30s 85ms/step - loss: 0.3763 - accuracy: 0.8985 - val_loss: 0.6823 - val_accuracy: 0.7990\nEpoch 20/20\n350/350 [==============================] - 30s 87ms/step - loss: 0.3536 - accuracy: 0.9020 - val_loss: 0.7560 - val_accuracy: 0.8020\nEpoch 1/20\n350/350 [==============================] - 25s 50ms/step - loss: 2.4177 - accuracy: 0.1364 - val_loss: 2.1334 - val_accuracy: 0.2960\nEpoch 2/20\n350/350 [==============================] - 16s 46ms/step - loss: 1.5725 - accuracy: 0.3868 - val_loss: 1.9436 - val_accuracy: 0.3410\nEpoch 3/20\n350/350 [==============================] - 16s 46ms/step - loss: 1.2766 - accuracy: 0.5162 - val_loss: 1.1987 - val_accuracy: 0.5480\nEpoch 4/20\n350/350 [==============================] - 16s 46ms/step - loss: 1.0933 - accuracy: 0.6040 - val_loss: 0.9855 - val_accuracy: 0.6960\nEpoch 5/20\n350/350 [==============================] - 16s 46ms/step - loss: 0.9346 - accuracy: 0.6972 - val_loss: 1.3103 - val_accuracy: 0.5700\nEpoch 6/20\n350/350 [==============================] - 16s 46ms/step - loss: 0.8453 - accuracy: 0.7313 - val_loss: 1.4844 - val_accuracy: 0.5660\nEpoch 7/20\n350/350 [==============================] - 16s 45ms/step - loss: 0.7655 - accuracy: 0.7647 - val_loss: 0.9718 - val_accuracy: 0.7040\nEpoch 8/20\n350/350 [==============================] - 16s 46ms/step - loss: 0.6903 - accuracy: 0.7900 - val_loss: 0.9010 - val_accuracy: 0.7350\nEpoch 9/20\n350/350 [==============================] - 16s 46ms/step - loss: 0.6225 - accuracy: 0.8127 - val_loss: 1.0045 - val_accuracy: 0.7120\nEpoch 10/20\n350/350 [==============================] - 17s 47ms/step - loss: 0.5676 - accuracy: 0.8332 - val_loss: 1.2045 - val_accuracy: 0.6580\nEpoch 11/20\n350/350 [==============================] - 16s 47ms/step - loss: 0.5466 - accuracy: 0.8416 - val_loss: 1.2771 - val_accuracy: 0.6480\nEpoch 12/20\n350/350 [==============================] - 17s 47ms/step - loss: 0.4760 - accuracy: 0.8682 - val_loss: 0.6980 - val_accuracy: 0.8000\nEpoch 13/20\n350/350 [==============================] - 16s 47ms/step - loss: 0.4211 - accuracy: 0.8823 - val_loss: 0.6659 - val_accuracy: 0.8040\nEpoch 14/20\n350/350 [==============================] - 17s 48ms/step - loss: 0.3978 - accuracy: 0.8887 - val_loss: 0.6643 - val_accuracy: 0.8100\nEpoch 15/20\n350/350 [==============================] - 16s 47ms/step - loss: 0.3697 - accuracy: 0.8982 - val_loss: 0.6578 - val_accuracy: 0.8120\nEpoch 16/20\n350/350 [==============================] - 17s 47ms/step - loss: 0.3566 - accuracy: 0.9018 - val_loss: 0.6514 - val_accuracy: 0.8140\nEpoch 17/20\n350/350 [==============================] - 16s 46ms/step - loss: 0.3510 - accuracy: 0.9032 - val_loss: 0.6503 - val_accuracy: 0.8140\nEpoch 18/20\n350/350 [==============================] - 17s 48ms/step - loss: 0.3274 - accuracy: 0.9131 - val_loss: 0.6531 - val_accuracy: 0.8170\nEpoch 19/20\n350/350 [==============================] - 16s 47ms/step - loss: 0.3121 - accuracy: 0.9153 - val_loss: 0.6497 - val_accuracy: 0.8210\nEpoch 20/20\n350/350 [==============================] - 17s 47ms/step - loss: 0.3090 - accuracy: 0.9176 - val_loss: 0.6553 - val_accuracy: 0.8180\n","output_type":"stream"}]}]}